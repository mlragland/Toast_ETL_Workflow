# ğŸ´ Toast ETL Transformation Requirements Analysis

Based on examination of legacy scripts in `/legacy_scripts` folder, this document outlines the comprehensive transformation requirements and schema mappings for each Toast CSV file.

## Overview of Transformation Requirements

The Toast ETL pipeline processes 7 CSV files exported from Toast POS system. Each file requires specific column mapping, data type conversions, and cleaning operations.

### Key Transformation Patterns

1. **Column Name Sanitization**: Original Toast CSV headers contain special characters (parentheses, slashes, spaces) that are invalid in BigQuery
2. **Date/Time Processing**: Multiple date/time formats need standardization
3. **String Type Preservation**: Certain ID columns need explicit string handling to prevent scientific notation
4. **Special Value Conversions**: Kitchen timing data requires custom parsing
5. **Missing Value Handling**: All null values filled with empty strings

---

## ğŸ“Š File-by-File Transformation Analysis

### 1. AllItemsReport.csv

**Purpose**: Menu item sales analysis and performance metrics

**Original â†’ Cleaned Column Mappings**:
```
"Master ID" â†’ "master_id"                           # âš ï¸ PROBLEMATIC: Contains spaces and parentheses
"Item ID" â†’ "item_id"
"Parent ID" â†’ "parent_id"
"Menu Name" â†’ "menu_name"
"Menu Group" â†’ "menu_group"
"Subgroup" â†’ "subgroup"
"Menu Item" â†’ "menu_item"
"Tags" â†’ "tags"
"Avg Price" â†’ "avg_price"
"Item Qty (incl voids)" â†’ "item_qty_incl_voids"    # âš ï¸ PROBLEMATIC: Contains parentheses
"% of Ttl Qty (incl voids)" â†’ "percent_ttl_qty_incl_voids"
"Gross Amount (incl voids)" â†’ "gross_amount_incl_voids"
"% of Ttl Amt (incl voids)" â†’ "percent_ttl_amt_incl_voids"
"Item Qty" â†’ "item_qty"
"Gross Amount" â†’ "gross_amount"
"Void Qty" â†’ "void_qty"
"Void Amount" â†’ "void_amount"
"Discount Amount" â†’ "discount_amount"
"Net Amount" â†’ "net_amount"
"# Orders" â†’ "num_orders"
"% of Ttl # Orders" â†’ "percent_ttl_num_orders"
"% Qty (Group)" â†’ "percent_qty_group"
"% Qty (Menu)" â†’ "percent_qty_menu"
"% Qty (All)" â†’ "percent_qty_all"
"% Net Amt (Group)" â†’ "percent_net_amt_group"
"% Net Amt (Menu)" â†’ "percent_net_amt_menu"
"% Net Amt (All)" â†’ "percent_net_amt_all"
```

**Special Processing**:
- Force `master_id`, `item_id`, `parent_id` to string type to prevent scientific notation
- Add `processing_date` column (DATE)

**BigQuery Schema**:
- 27 columns total (26 data + 1 processing_date)
- Mix of STRING, FLOAT, INTEGER, DATE types
- All columns NULLABLE

---

### 2. CheckDetails.csv

**Purpose**: Individual check/receipt details and customer information

**Original â†’ Cleaned Column Mappings**:
```
"Customer Id" â†’ "customer_id"
"Customer" â†’ "customer"
"Customer Phone" â†’ "customer_phone"
"Customer Email" â†’ "customer_email"
"Location Code" â†’ "location_code"
"Opened Date" â†’ "opened_date"
"Opened Time" â†’ "opened_time"
"Item Description" â†’ "item_description"
"Server" â†’ "server"
"Tax" â†’ "tax"
"Tender" â†’ "tender"
"Check Id" â†’ "check_id"
"Check #" â†’ "check_number"
"Total" â†’ "total"
"Customer Family" â†’ "customer_family"
"Table Size" â†’ "table_size"
"Discount" â†’ "discount"
"Reason of Discount" â†’ "reason_of_discount"
"Link" â†’ "link"
```

**Special Processing**:
- `opened_date` â†’ DATE format (YYYY-MM-DD)
- `opened_time` â†’ TIME format (HH:MM:SS)
- Add `processing_date` column (DATE)

**BigQuery Schema**:
- 20 columns total (19 data + 1 processing_date)
- Mix of STRING, FLOAT, INTEGER, DATE, TIME types

---

### 3. CashEntries.csv

**Purpose**: Cash drawer transactions and employee actions

**Original â†’ Cleaned Column Mappings**:
```
"Location" â†’ "location"
"Entry Id" â†’ "entry_id"                             # REQUIRED field
"Created Date" â†’ "created_date"
"Action" â†’ "action"
"Amount" â†’ "amount"
"Cash Drawer" â†’ "cash_drawer"
"Payout Reason" â†’ "payout_reason"
"No Sale Reason" â†’ "no_sale_reason"
"Comment" â†’ "comment"
"Employee" â†’ "employee"
"Employee 2" â†’ "employee_2"
```

**Special Processing**:
- `created_date` â†’ DATETIME format (YYYY-MM-DD HH:MM:SS)
- `entry_id` is REQUIRED (only non-nullable field)
- Add `processing_date` column (DATE)

**BigQuery Schema**:
- 12 columns total (11 data + 1 processing_date)
- Mix of STRING, FLOAT, DATETIME, DATE types

---

### 4. ItemSelectionDetails.csv

**Purpose**: Individual item selections within orders

**Original â†’ Cleaned Column Mappings**:
```
"Location" â†’ "location"
"Order Id" â†’ "order_id"
"Order #" â†’ "order_number"
"Sent Date" â†’ "sent_date"
"Order Date" â†’ "order_date"
"Check Id" â†’ "check_id"
"Server" â†’ "server"
"Table" â†’ "table"
"Dining Area" â†’ "dining_area"
"Service" â†’ "service"
"Dining Option" â†’ "dining_option"
"Item Selection Id" â†’ "item_selection_id"
"Item Id" â†’ "item_id"
"Master Id" â†’ "master_id"
"SKU" â†’ "sku"
"PLU" â†’ "plu"
"Menu Item" â†’ "menu_item"
"Menu Subgroup(s)" â†’ "menu_subgroup"                # âš ï¸ PROBLEMATIC: Contains parentheses
"Menu Group" â†’ "menu_group"
"Menu" â†’ "menu"
"Sales Category" â†’ "sales_category"
"Gross Price" â†’ "gross_price"
"Discount" â†’ "discount"
"Net Price" â†’ "net_price"
"Qty" â†’ "quantity"
"Tax" â†’ "tax"
"Void?" â†’ "void"
"Deferred" â†’ "deferred"
"Tax Exempt" â†’ "tax_exempt"
"Tax Inclusion Option" â†’ "tax_inclusion_option"
"Dining Option Tax" â†’ "dining_option_tax"
"Tab Name" â†’ "tab_name"
```

**Special Processing**:
- `sent_date`, `order_date` â†’ DATETIME format (YYYY-MM-DD HH:MM:SS)
- Boolean fields: `void`, `deferred`, `tax_exempt`
- Add `processing_date` column (DATE)

**BigQuery Schema**:
- 33 columns total (32 data + 1 processing_date)
- Mix of STRING, FLOAT, INTEGER, DATETIME, BOOLEAN, DATE types

---

### 5. KitchenTimings.csv

**Purpose**: Kitchen order fulfillment timing metrics

**Original â†’ Cleaned Column Mappings**:
```
"Location" â†’ "location"
"ID" â†’ "id"
"Server" â†’ "server"
"Check #" â†’ "check_number"
"Table" â†’ "table"
"Check Opened" â†’ "check_opened"
"Station" â†’ "station"
"Expediter Level" â†’ "expediter_level"
"Fired Date" â†’ "fired_date"
"Fulfilled Date" â†’ "fulfilled_date"
"Fulfillment Time" â†’ "fulfillment_time"             # Special parsing required
"Fulfilled By" â†’ "fulfilled_by"
```

**Special Processing**:
- `check_opened`, `fired_date`, `fulfilled_date` â†’ DATETIME format
- **Critical**: `fulfillment_time` requires custom parsing from "X hours, Y minutes, Z seconds" â†’ total minutes (FLOAT)
- Add `processing_date` column (DATE)

**Fulfillment Time Conversion Logic**:
```python
def convert_to_minutes(time_str):
    # Parses "2 hours, 15 minutes, 30 seconds" â†’ "135.5"
    # Handles missing components gracefully
    # Returns string representation of float
```

**BigQuery Schema**:
- 13 columns total (12 data + 1 processing_date)
- Mix of STRING, INTEGER, DATETIME, FLOAT, DATE types

---

### 6. OrderDetails.csv

**Purpose**: High-level order information and totals

**Original â†’ Cleaned Column Mappings**:
```
"Location" â†’ "location"
"Order Id" â†’ "order_id"
"Order #" â†’ "order_number"
"Checks" â†’ "checks"
"Opened" â†’ "opened"
"# of Guests" â†’ "guest_count"
"Tab Names" â†’ "tab_names"
"Server" â†’ "server"
"Table" â†’ "table"
"Revenue Center" â†’ "revenue_center"
"Dining Area" â†’ "dining_area"
"Service" â†’ "service"
"Dining Options" â†’ "dining_options"
"Discount Amount" â†’ "discount_amount"
"Amount" â†’ "amount"
"Tax" â†’ "tax"
"Tip" â†’ "tip"
"Gratuity" â†’ "gratuity"
"Total" â†’ "total"
"Voided" â†’ "voided"
"Paid" â†’ "paid"
"Closed" â†’ "closed"
"Duration (Opened to Paid)" â†’ "duration_opened_to_paid"  # âš ï¸ PROBLEMATIC: Contains parentheses
"Order Source" â†’ "order_source"
```

**Special Processing**:
- `opened`, `paid`, `closed` â†’ DATETIME format
- `duration_opened_to_paid` â†’ TIME format (HH:MM:SS)
- `voided` â†’ BOOLEAN
- Add `processing_date` column (DATE)

**BigQuery Schema**:
- 25 columns total (24 data + 1 processing_date)
- Mix of STRING, INTEGER, FLOAT, DATETIME, BOOLEAN, TIME, DATE types

---

### 7. PaymentDetails.csv

**Purpose**: Payment transaction details and methods

**Original â†’ Cleaned Column Mappings**:
```
"Location" â†’ "location"
"Payment Id" â†’ "payment_id"
"Order Id" â†’ "order_id"
"Order #" â†’ "order_number"
"Paid Date" â†’ "paid_date"
"Order Date" â†’ "order_date"
"Check Id" â†’ "check_id"
"Check #" â†’ "check_number"
"Tab Name" â†’ "tab_name"
"Server" â†’ "server"
"Table" â†’ "table"
"Dining Area" â†’ "dining_area"
"Service" â†’ "service"
"Dining Option" â†’ "dining_option"
"House Acct #" â†’ "house_account_number"
"Amount" â†’ "amount"
"Tip" â†’ "tip"
"Gratuity" â†’ "gratuity"
"Total" â†’ "total"
"Swiped Card Amount" â†’ "swiped_card_amount"
"Keyed Card Amount" â†’ "keyed_card_amount"
"Amount Tendered" â†’ "amount_tendered"
"Refunded" â†’ "refunded"
"Refund Date" â†’ "refund_date"
"Refund Amount" â†’ "refund_amount"
"Refund Tip Amount" â†’ "refund_tip_amount"
"Void User" â†’ "void_user"
"Void Approver" â†’ "void_approver"
"Void Date" â†’ "void_date"
"Status" â†’ "status"
"Type" â†’ "type"
"Cash Drawer" â†’ "cash_drawer"
"Card Type" â†’ "card_type"
"Other Type" â†’ "other_type"
"Email" â†’ "email"
"Phone" â†’ "phone"
"Last 4 Card Digits" â†’ "last_4_card_digits"
"V/MC/D Fees" â†’ "vmcd_fees"                         # âš ï¸ PROBLEMATIC: Contains slashes
"Room Info" â†’ "room_info"
"Receipt" â†’ "receipt"
"Source" â†’ "source"
"Last 4 Gift Card Digits" â†’ "last_4_gift_card_digits"
"First 5 Gift Card Digits" â†’ "first_5_gift_card_digits"
```

**Special Processing**:
- `paid_date`, `refund_date`, `order_date`, `void_date` â†’ DATETIME format
- Add `processing_date` column (DATE)

**BigQuery Schema**:
- 44 columns total (43 data + 1 processing_date)
- Mix of STRING, FLOAT, DATETIME, DATE types

---

## âš ï¸ Critical Column Name Issues Identified

Based on Phase 2 testing, these original column names cause BigQuery failures:

### **Files with Problematic Column Names**:

1. **AllItemsReport.csv**:
   - `"Item Qty (incl voids)"` - parentheses not allowed

2. **PaymentDetails.csv**:
   - `"V/MC/D Fees"` - slashes not allowed

3. **OrderDetails.csv**:
   - `"Duration (Opened to Paid)"` - parentheses not allowed

4. **ItemSelectionDetails.csv**:
   - `"Menu Subgroup(s)"` - parentheses not allowed

### **Solution Required for Phase 3**:
Implement column name sanitization that:
- Removes or replaces parentheses: `()` â†’ `_` or remove
- Removes or replaces slashes: `/` â†’ `_` or remove
- Handles other special characters consistently

---

## ğŸ”„ Transformation Processing Flow

### Current Legacy Process:
1. **Extract**: SFTP download of 7 CSV files
2. **Transform**: Column renaming + data type conversion
3. **Load**: Upload to GCS â†’ BigQuery load with JSON schemas

### Data Type Conversion Rules:
- **DATE**: `YYYY-MM-DD` format
- **DATETIME**: `YYYY-MM-DD HH:MM:SS` format  
- **TIME**: `HH:MM:SS` format
- **FLOAT**: Kitchen timing special conversion
- **STRING**: Default for text, explicit for IDs
- **BOOLEAN**: True/False values
- **INTEGER**: Numeric counters

### Missing Value Handling:
- All null/empty values â†’ empty string `""`
- Ensures consistent BigQuery loading

---

## ğŸ“ˆ Schema Summary by File

| File | Columns | Key Data Types | Special Processing |
|------|---------|---------------|-------------------|
| AllItemsReport | 28 | STRING, FLOAT, INTEGER, DATE | String type preservation |
| CheckDetails | 20 | STRING, FLOAT, INTEGER, DATE, TIME | Date/time separation |
| CashEntries | 12 | STRING, FLOAT, DATETIME, DATE | Required entry_id |
| ItemSelectionDetails | 33 | STRING, FLOAT, INTEGER, DATETIME, BOOLEAN, DATE | Boolean conversions |
| KitchenTimings | 13 | STRING, INTEGER, DATETIME, FLOAT, DATE | Time parsing to minutes |
| OrderDetails | 25 | STRING, INTEGER, FLOAT, DATETIME, BOOLEAN, TIME, DATE | Duration as TIME |
| PaymentDetails | 44 | STRING, FLOAT, DATETIME, DATE | Most complex schema |

**Total**: 175 columns across 7 tables, requiring 23 datetime conversions and 4 special transformations.

---

## ğŸ¯ Phase 3 Implementation Requirements

Based on this analysis, Phase 3 (Data Transformation Layer) must implement:

1. **Column Name Sanitization**: Handle special characters in original headers
2. **Robust Date/Time Parsing**: 23 datetime field conversions
3. **Special Value Processing**: Kitchen timing minutes conversion
4. **Data Type Enforcement**: Prevent scientific notation in ID fields
5. **Validation Logic**: Ensure all transformations complete successfully
6. **Error Handling**: Graceful handling of malformed data

This comprehensive transformation layer will bridge the gap between raw Toast CSV exports and BigQuery-ready data.